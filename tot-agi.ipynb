{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain\n",
    "!pip -q install guardrails-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import getpass\n",
    "\n",
    "from rich import print\n",
    "\n",
    "from langchain.output_parsers import GuardrailsOutputParser\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_problem = input(\"Enter the problem: \")\n",
    "input_nodes = input(\"Enter the nodes: \")\n",
    "input_iterations = input(\"Enter the iterations: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.9 , model=\"gpt-3.5-turbo-16k\", client=any , openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "formated_problem = {\n",
    "  \"problem\": \"problem\",\n",
    "  \"approach\": [\n",
    "    {\n",
    "      \"approach\": \"\",\n",
    "      \"score\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"approach\": \"\",\n",
    "      \"score\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"approach\": \"\",\n",
    "      \"score\": \"\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are an AI who is really good at solving problems. You always think step by step and come up with different approaches to solve a problem\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\n",
    "        f\"\"\"\n",
    "        Given this problem: {input_problem}\n",
    "        let solve the problem step by step.\n",
    "        you have {input_iterations} iterations to solve it.\n",
    "        come up with {input_nodes} different approaches to solve it.\n",
    "        \n",
    "        give each approach a score from 0 to 10 based on how good it is.\n",
    "        \n",
    "        give it to me in this format:\n",
    "        {str(formated_problem)}\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "step1 = chat(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_rail = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<output>\n",
    "    <string name=\"problem\" description=\"problem specified\" />\n",
    "    <list name=\"approaches\" description=\"List of different approaches to solve the problem\">\n",
    "        <object>\n",
    "            <string name=\"approach\" description=\"the approach\"/>\n",
    "            <integer name=\"score\" format=\"valid-range: 0 10\" />\n",
    "        </object>\n",
    "    </list>\n",
    "</output>\n",
    "\n",
    "<prompt>\n",
    "\n",
    "given the following problem and steps to solve the problem, please extract the problem and a list of different approaches \n",
    "\n",
    "{{approach}}\n",
    "\n",
    "@complete_json_suffix_v2\n",
    "</prompt>\n",
    "</rail>\n",
    "\"\"\"\n",
    "\n",
    "output_parser = GuardrailsOutputParser.from_rail_string(extractor_rail)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=output_parser.guard.base_prompt,\n",
    "    input_variables=output_parser.guard.prompt.variable_names,\n",
    ")\n",
    "\n",
    "model = OpenAI(temperature=0 , openai_api_key=OPENAI_API_KEY) # type: ignore\n",
    "# model = OpenAI(temperature=0)\n",
    "print(step1)\n",
    "solution = model(prompt.format_prompt(approach=step1).to_string())\n",
    "solution = output_parser.parse(solution)\n",
    "print(solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
